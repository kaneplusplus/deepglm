---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# dlrm

<!-- badges: start -->
[![Lifecycle: experimental](https://img.shields.io/badge/lifecycle-experimental-orange.svg)](https://www.tidyverse.org/lifecycle/#experimental)
<!-- badges: end -->

The goal of dlm is to ...

## Installation

You can install the development version of this package from 
[GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("kaneplusplus/dlm")
```

## Regression onto a categorical variable

```{r}
library(keras)
library(dlrm)

# Regress iris variables onto Species (categorical) and get the accuracy.
fit_dlmcat <- dlr(iris, Species ~ ., hidden_layers = 16, epochs = 2000)
sum(iris$Species == dlr_predict(iris, fit_dlmcat)) / nrow(iris)
```

## Regression onto a continous variable

```{r example}
# Regress iris variables onto Sepal.Length using a linear model and get the 
# in-sample prediction accuracy.
fit_linear <- lm(Sepal.Length ~ ., iris)
sd(predict(fit_linear, iris))

# Perform the same operation with a deep learner with two hidden layers
# with 24 and 2 nodes respectively.
fit_dlmc <- dlr(iris, Sepal.Length ~., hidden_layers = c(24, 2))
sd(iris$Sepal.Length - dlr_predict(iris, fit_dlmc))
```

## A deep survival analysis

```{r survival}
library(survival)
library(dplyr)

data(lung)

# Handle the categorical variables in lung
lung <- lung %>%
  mutate(status = status - 1,
         sex = as.factor(sex),
         ph.ecog = as.factor(ph.ecog))

# Fit the deep survival model.
dc_fit <- dlcp(
  lung,
  Surv(time, status) ~ sex + age + meal.cal + wt.loss + ph.ecog,
  epochs = 150,
  validation_split = .2)

dl_weights <- get_weights(dc_fit$model)[[1]]

# Compare the deep survival model coefficients to coxph.
cfit <- summary(coxph(Surv(time, status) ~ sex + age + meal.cal + wt.loss + ph.ecog, lung))$conf.int
comp <- round(cbind(dl_weights, log(cfit)[,-2]), 3)
colnames(comp) <- c("Deep Learner Coefs", "Cox Coef", "Cox Lower .95", "Cox Upper .95")
comp

# Plot the training history.
plot_training_history(dc_fit)
```

```{r echo = FALSE, eval = FALSE}
library(ggplot2)
library(dplyr)

iris %>% 
  metric_space_embedding(fit_dlmc) %>%
  `colnames<-`(c("X", "Y")) %>%
  as_tibble() %>%
  mutate(Species = iris$Species) %>%
  ggplot(aes(x = X, y = Y, color = Species)) +
    geom_point() +
    theme_bw()

```
